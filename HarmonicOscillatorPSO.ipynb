{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv+1QKf5GsNCo8sUJz0Tpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorvalente/HarmonicOscillatorPSO/blob/main/HarmonicOscillatorPSO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpROX2cmznmg",
        "outputId": "e5b1481a-55c6-46b3-82a0-1b2404fb82ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing SPHERE Swarm Intelligence System...\n",
            "Current Time: 2025-03-31 11:18:50\n",
            "Initialized 2 agents.\n",
            "Initialized SwarmQueen.\n",
            "\n",
            "--- Starting Data Loading and Processing ---\n",
            "Target Subject: 00001\n",
            "Attempting to load data from: /content/SPHERE_unzipped\n",
            "Attempting to load accelerometer for subject 00001 from base path: /content/SPHERE_unzipped\n",
            "  Using subject data folder: /content/SPHERE_unzipped/train/00001\n",
            "  Loading data from: /content/SPHERE_unzipped/train/00001/acceleration.csv\n",
            "  Found timestamp column: 't'\n",
            "  Converting timestamp column (assuming units are seconds)...\n",
            "  ...Loaded 35710 rows.\n",
            "Attempting to load pir for subject 00001 from base path: /content/SPHERE_unzipped\n",
            "  Using subject data folder: /content/SPHERE_unzipped/train/00001\n",
            "  Loading data from: /content/SPHERE_unzipped/train/00001/pir.csv\n",
            "  Using 'start' column as timestamp index for pir.\n",
            "  ...Processed 115 pir rows.\n",
            "Attempting to load annotations for subject 00001 from base path: /content/SPHERE_unzipped\n",
            "  Using subject data folder: /content/SPHERE_unzipped/train/00001\n",
            "  Found annotation files: ['annotations_0.csv', 'annotations_1.csv']\n",
            "    Successfully loaded annotations_0.csv\n",
            "    Successfully loaded annotations_1.csv\n",
            "  Concatenated 2 annotation files into one DataFrame.\n",
            "  Using 'start' column as timestamp index for annotations.\n",
            "  ...Processed 744 annotations rows.\n",
            "\n",
            "--- Essential data (Accel, Annotations) loaded successfully. Proceeding... ---\n",
            "--- PIR data loaded successfully. ---\n",
            "Synchronizing data streams to 50ms frequency...\n",
            "  Processing ACCELEROMETER...\n",
            "    Resampled ACCELEROMETER to 36478 rows.\n",
            "  Processing PIR...\n",
            "    Resampled PIR to 36327 rows.\n",
            "  Merging streams...\n",
            "    Merged PIR, shape now: (72805, 9)\n",
            "  Forward-filling missing values...\n",
            "  Final synchronized shape: (72805, 9)\n",
            "Sorting annotations index...\n",
            "\n",
            "--- Processing Windows ---\n",
            "Creating time windows (size: 2.0s, overlap: 1.0s)...\n",
            "  Processed 100 windows... Time: 00:01:41.000 Pred: t_sit_stand (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 200 windows... Time: 00:03:21.000 Pred: a_jump (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 300 windows... Time: 00:05:01.000 Pred: t_sit_stand (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 400 windows... Time: 00:06:41.000 Pred: t_sit_lie (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 500 windows... Time: 00:08:21.000 Pred: a_ascend (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 600 windows... Time: 00:10:01.000 Pred: a_walk (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 700 windows... Time: 00:11:41.000 Pred: a_walk (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 800 windows... Time: 00:13:21.000 Pred: t_turn (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 900 windows... Time: 00:15:01.000 Pred: a_ascend (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1000 windows... Time: 00:16:41.000 Pred: t_kneel_stand (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1100 windows... Time: 00:18:21.000 Pred: a_ascend (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1200 windows... Time: 00:20:01.000 Pred: t_turn (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1300 windows... Time: 00:21:41.000 Pred: a_descend (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1400 windows... Time: 00:23:21.000 Pred: a_descend (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1500 windows... Time: 00:25:01.000 Pred: a_descend (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1600 windows... Time: 00:26:41.000 Pred: a_walk (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1700 windows... Time: 00:28:21.000 Pred: a_walk (GT: N/A) Loc: UNKNOWN\n",
            "  Processed 1800 windows... Time: 00:30:01.000 Pred: a_descend (GT: N/A) Loc: UNKNOWN\n",
            "Generated 1822 windows.\n",
            "\n",
            "--- Finished processing 1822 windows in 17.58 seconds ---\n",
            "\n",
            "--- Evaluation Results ---\n",
            "Collected 0 predictions with valid ground truth.\n",
            "\n",
            "Evaluation failed: No valid ground truth labels were found.\n",
            "Check annotation loading and GT lookup logic.\n",
            "\n",
            "System processing finished (or terminated due to loading/sync error).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from enum import Enum, auto\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "from collections import defaultdict, deque\n",
        "import time\n",
        "from scipy.fft import rfft, rfftfreq # For frequency domain features\n",
        "import traceback # For detailed error printing\n",
        "\n",
        "# --- Configuration & Enums ---\n",
        "\n",
        "class SensorType(Enum):\n",
        "    ACCELEROMETER = auto()\n",
        "    PIR = auto()\n",
        "    RSSI = auto()\n",
        "    VIDEO = auto()\n",
        "\n",
        "class ActivityType(Enum):\n",
        "    AMBULATION = auto()\n",
        "    POSTURE = auto()\n",
        "    TRANSITION = auto()\n",
        "\n",
        "class Location(Enum):\n",
        "    BATH = auto()\n",
        "    BED1 = auto()\n",
        "    BED2 = auto()\n",
        "    HALL = auto()\n",
        "    KITCHEN = auto()\n",
        "    LIVING = auto()\n",
        "    STAIRS = auto()\n",
        "    STUDY = auto()\n",
        "    TOILET = auto()\n",
        "    UNKNOWN = auto()\n",
        "\n",
        "SPHERE_ACTIVITIES = {\n",
        "    'a_ascend': ActivityType.AMBULATION, 'a_descend': ActivityType.AMBULATION,\n",
        "    'a_jump': ActivityType.AMBULATION, 'a_loadwalk': ActivityType.AMBULATION,\n",
        "    'a_walk': ActivityType.AMBULATION, 'p_bent': ActivityType.POSTURE,\n",
        "    'p_kneel': ActivityType.POSTURE, 'p_lie': ActivityType.POSTURE,\n",
        "    'p_sit': ActivityType.POSTURE, 'p_squat': ActivityType.POSTURE,\n",
        "    'p_stand': ActivityType.POSTURE, 't_bend': ActivityType.TRANSITION,\n",
        "    't_kneel_stand': ActivityType.TRANSITION, 't_lie_sit': ActivityType.TRANSITION,\n",
        "    't_sit_lie': ActivityType.TRANSITION, 't_sit_stand': ActivityType.TRANSITION,\n",
        "    't_stand_kneel': ActivityType.TRANSITION, 't_stand_sit': ActivityType.TRANSITION,\n",
        "    't_straighten': ActivityType.TRANSITION, 't_turn': ActivityType.TRANSITION\n",
        "}\n",
        "SPHERE_ACTIVITY_NAMES = list(SPHERE_ACTIVITIES.keys())\n",
        "\n",
        "SPHERE_LOCATIONS = ['bath', 'bed1', 'bed2', 'hall', 'kitchen', 'living', 'stairs', 'study', 'toilet']\n",
        "SPHERE_LOCATION_ENUM_MAP = {name: Location[name.upper()] for name in SPHERE_LOCATIONS}\n",
        "SPHERE_LOCATION_ENUM_MAP['UNKNOWN'] = Location.UNKNOWN\n",
        "\n",
        "# --- Data Handling Utilities (Revised v4 - Step 1) ---\n",
        "\n",
        "def load_sphere_data(data_path, subject_id, data_type):\n",
        "    \"\"\"\n",
        "    Loads specific sensor data or annotations for a subject,\n",
        "    adapted for potential SPHERE challenge structures (v4 - handles PIR start/end).\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to load {data_type} for subject {subject_id} from base path: {data_path}\")\n",
        "    file_path = None # Used for logging the primary file path loaded\n",
        "    df = None      # DataFrame to be loaded\n",
        "\n",
        "    # --- Path and Filename Logic ---\n",
        "    data_type_lower = data_type.lower()\n",
        "\n",
        "    # Determine base subject folder (try train, test, then base)\n",
        "    subject_folder_options = [\n",
        "        os.path.join(data_path, 'train', subject_id),\n",
        "        os.path.join(data_path, 'test', subject_id),\n",
        "        os.path.join(data_path, subject_id)\n",
        "    ]\n",
        "    subject_base_path = None\n",
        "    for folder_option in subject_folder_options:\n",
        "        if os.path.isdir(folder_option):\n",
        "            subject_base_path = folder_option\n",
        "            print(f\"  Using subject data folder: {subject_base_path}\")\n",
        "            break\n",
        "\n",
        "    if subject_base_path is None:\n",
        "         # If loading annotations, maybe they are not in a subject folder?\n",
        "         if data_type_lower == 'annotations':\n",
        "              print(\"  Subject folder not found, checking for annotations in base/train paths...\")\n",
        "              # Let the annotation-specific logic below handle finding the file elsewhere\n",
        "              pass\n",
        "         else:\n",
        "              # For sensor data, subject folder is usually required\n",
        "              print(f\"Error: Could not find subject folder for {subject_id} in train/, test/, or base directory relative to {data_path}.\")\n",
        "              return None\n",
        "\n",
        "    # --- Specific Loading Logic per Type ---\n",
        "    if data_type_lower == 'annotations':\n",
        "        # Annotations are inside the subject's folder, named annotations_*.csv (based on find output)\n",
        "        annotation_files = []\n",
        "        if subject_base_path: # Check subject path first\n",
        "             annotation_pattern = os.path.join(subject_base_path, 'annotations_*.csv')\n",
        "             annotation_files = sorted(glob.glob(annotation_pattern))\n",
        "\n",
        "        # If not found in subject folder, check other common locations\n",
        "        if not annotation_files:\n",
        "             print(f\"  Annotations not found in subject folder, checking other locations...\")\n",
        "             possible_paths = [\n",
        "                 os.path.join(data_path, 'train', f'{subject_id}_annotations.csv'),\n",
        "                 os.path.join(data_path, 'train', 'annotations.csv'),\n",
        "                 os.path.join(data_path, 'annotations', f'{subject_id}.csv'),\n",
        "                 os.path.join(data_path, 'annotations.csv')\n",
        "             ]\n",
        "             for p in possible_paths:\n",
        "                 if os.path.exists(p):\n",
        "                     annotation_files = [p] # Treat as single file if found this way\n",
        "                     print(f\"  Found potential annotation file at: {p}\")\n",
        "                     break # Take the first one found\n",
        "\n",
        "        if not annotation_files:\n",
        "            print(f\"Error: No annotation files found for subject {subject_id} in subject folder or common locations.\")\n",
        "            return None\n",
        "\n",
        "        print(f\"  Found annotation files: { [os.path.basename(f) for f in annotation_files] }\")\n",
        "        file_path = annotation_files[0] # Use first file path for logging purposes\n",
        "\n",
        "        # Load and concatenate all found annotation files\n",
        "        all_annotations_df = []\n",
        "        for f in annotation_files:\n",
        "             try:\n",
        "                 df_part = pd.read_csv(f)\n",
        "                 all_annotations_df.append(df_part)\n",
        "                 print(f\"    Successfully loaded {os.path.basename(f)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Warning: Could not load or read annotation file {f}: {e}\")\n",
        "\n",
        "        if not all_annotations_df:\n",
        "             print(f\"Error: Failed to load any valid data from found annotation files.\")\n",
        "             return None\n",
        "\n",
        "        # Concatenate into a single DataFrame\n",
        "        df = pd.concat(all_annotations_df, ignore_index=True)\n",
        "        print(f\"  Concatenated {len(annotation_files)} annotation files into one DataFrame.\")\n",
        "\n",
        "    else:\n",
        "        # Sensor data loading (requires subject_base_path)\n",
        "        if subject_base_path is None: return None # Should have already exited, but safety\n",
        "\n",
        "        filename_map = {\n",
        "            'accelerometer': ['acceleration.csv', 'acc*.csv'],\n",
        "            'pir': ['pir.csv'],\n",
        "            'rssi': ['rssi*.csv'],\n",
        "            'video_features': ['video_features*.csv']\n",
        "        }\n",
        "        patterns = filename_map.get(data_type_lower)\n",
        "        if not patterns:\n",
        "            print(f\"Error: Unknown data_type '{data_type_lower}' for sensor loading.\")\n",
        "            return None\n",
        "\n",
        "        # Find matching files using glob\n",
        "        found_files = []\n",
        "        for pattern in patterns:\n",
        "             matching_files = glob.glob(os.path.join(subject_base_path, pattern))\n",
        "             if matching_files:\n",
        "                 found_files.extend(matching_files)\n",
        "\n",
        "        if not found_files:\n",
        "            print(f\"Warning: No file found matching patterns '{patterns}' for {data_type_lower} in {subject_base_path}\")\n",
        "            return None\n",
        "\n",
        "        # File Selection Logic\n",
        "        primary_target = os.path.join(subject_base_path, patterns[0])\n",
        "        if primary_target in found_files:\n",
        "            file_path = primary_target\n",
        "        else:\n",
        "            file_path = sorted(found_files)[0]\n",
        "            print(f\"  Note: Using first matched file: {os.path.basename(file_path)}\")\n",
        "\n",
        "        # Load the selected sensor data file\n",
        "        print(f\"  Loading data from: {file_path}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path)\n",
        "        except Exception as e:\n",
        "             print(f\"Error loading sensor data file {file_path}: {e}\")\n",
        "             traceback.print_exc()\n",
        "             return None\n",
        "\n",
        "    # --- Common Processing (Timestamping, Indexing) ---\n",
        "    if df is None:\n",
        "        print(f\"Error: DataFrame is None after loading attempt for {data_type_lower}.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # --- Timestamp Handling ---\n",
        "        # Removed PIR debug print here\n",
        "        timestamp_cols_to_try = ['t', 'timestamp', 'time']\n",
        "        timestamp_col = None\n",
        "        for col in timestamp_cols_to_try:\n",
        "            if col in df.columns:\n",
        "                timestamp_col = col\n",
        "                print(f\"  Found timestamp column: '{timestamp_col}'\")\n",
        "                break\n",
        "\n",
        "        # Handle annotation or PIR files which might use 'start'/'end' instead\n",
        "        if timestamp_col is None and (data_type_lower == 'annotations' or data_type_lower == 'pir'):\n",
        "            if 'start' in df.columns and 'end' in df.columns:\n",
        "                 timestamp_col = 'start' # Use start as the index timestamp\n",
        "                 print(f\"  Using 'start' column as timestamp index for {data_type_lower}.\")\n",
        "                 # Convert start/end to datetime (assuming seconds, VERIFY unit)\n",
        "                 df['start'] = pd.to_datetime(df['start'], unit='s') # <<< VERIFY UNIT\n",
        "                 df['end'] = pd.to_datetime(df['end'], unit='s')     # <<< VERIFY UNIT\n",
        "                 df = df.set_index('start').sort_index()\n",
        "                 print(f\"  ...Processed {len(df)} {data_type_lower} rows.\")\n",
        "                 return df # Return DataFrame indexed by start time\n",
        "            else:\n",
        "                 print(f\"Error: {data_type_lower.capitalize()} file lacks 'start'/'end' and standard timestamp columns.\")\n",
        "                 return None\n",
        "        elif timestamp_col is None:\n",
        "            # If no standard timestamp and not annotation/PIR with start/end\n",
        "            print(f\"Error: Could not find a suitable timestamp column {timestamp_cols_to_try} in {file_path}\")\n",
        "            return None\n",
        "\n",
        "        # Rename the found timestamp column to 'timestamp' for consistency\n",
        "        if timestamp_col != 'timestamp':\n",
        "            df = df.rename(columns={timestamp_col: 'timestamp'})\n",
        "\n",
        "        # Convert timestamp column to datetime (assuming seconds, VERIFY unit)\n",
        "        print(f\"  Converting timestamp column (assuming units are seconds)...\") # <<< VERIFY UNIT\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s') # Adjust unit if needed ('ms')\n",
        "\n",
        "        # Set timestamp as index for easier time-based operations\n",
        "        df = df.set_index('timestamp').sort_index()\n",
        "\n",
        "        print(f\"  ...Loaded {len(df)} rows.\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing DataFrame for {file_path if file_path else data_type}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "def synchronize_data(data_streams, resample_freq='50ms'):\n",
        "    \"\"\"\n",
        "    Synchronizes multiple data streams (dict of {'sensor_type': DataFrame with datetime index}).\n",
        "    Resamples to a common frequency and forward-fills missing values.\n",
        "    \"\"\"\n",
        "    print(f\"Synchronizing data streams to {resample_freq} frequency...\")\n",
        "    combined_df = None\n",
        "    processed_streams = {}\n",
        "\n",
        "    for sensor_type, df in data_streams.items():\n",
        "        if df is None or df.empty:\n",
        "            print(f\"  Skipping empty stream: {sensor_type.name}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  Processing {sensor_type.name}...\")\n",
        "        # Ensure datetime index\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "            # If index is not datetime (e.g., PIR loaded with start/end but not indexed yet)\n",
        "            # This part might need adjustment based on how PIR df is returned if not indexed by time\n",
        "            print(f\"Error: DataFrame for {sensor_type.name} does not have a DatetimeIndex.\")\n",
        "            continue # Skip streams without proper time index\n",
        "\n",
        "        # Resample to the target frequency\n",
        "        try:\n",
        "            if sensor_type == SensorType.PIR:\n",
        "                # How to resample PIR data indexed by 'start' time?\n",
        "                # Option 1: Create a time series indicating presence during intervals\n",
        "                # Requires 'end' column. Create a new series aligned with target frequency.\n",
        "                if 'end' in df.columns:\n",
        "                     min_time = df.index.min()\n",
        "                     max_time = df['end'].max()\n",
        "                     # Create target time index\n",
        "                     target_index = pd.date_range(start=min_time, end=max_time, freq=resample_freq)\n",
        "                     # Create empty dataframe with target index\n",
        "                     resampled_df_pir = pd.DataFrame(0, index=target_index, columns=df.columns.drop('end', errors='ignore'))\n",
        "\n",
        "                     # Mark presence (e.g., set to 1) for intervals where PIR was active\n",
        "                     for start, row in df.iterrows():\n",
        "                          end = row['end']\n",
        "                          # Find target index points within the [start, end) interval\n",
        "                          active_indices = target_index[(target_index >= start) & (target_index < end)]\n",
        "                          # Set relevant columns (e.g., location columns if PIR has them) to 1\n",
        "                          # Assuming PIR columns are location names\n",
        "                          location_cols = [col for col in df.columns if col in SPHERE_LOCATIONS]\n",
        "                          if location_cols:\n",
        "                               # Use the 'name' column from PIR data if it indicates location\n",
        "                               if 'name' in row.index and row['name'] in location_cols:\n",
        "                                    resampled_df_pir.loc[active_indices, row['name']] = 1\n",
        "                               else: # If no 'name' or name mismatch, maybe set all location cols? Risky.\n",
        "                                    # resampled_df_pir.loc[active_indices, location_cols] = 1 # Or handle differently\n",
        "                                    pass # For now, only mark if name matches a location column\n",
        "                          else: # If PIR data doesn't have location columns, what to do? Mark a generic 'pir_active'?\n",
        "                               # resampled_df_pir['pir_active'] = 0 # Add column if needed\n",
        "                               # resampled_df_pir.loc[active_indices, 'pir_active'] = 1\n",
        "                               pass # Skip if structure unknown\n",
        "\n",
        "                     resampled_df = resampled_df_pir.fillna(0) # Fill any NaNs from creation\n",
        "                else:\n",
        "                     print(f\"Warning: Cannot resample PIR data for {sensor_type.name} without 'end' column. Skipping.\")\n",
        "                     continue\n",
        "            else:\n",
        "                # Resample others: take the mean\n",
        "                resampled_df = df.resample(resample_freq).mean()\n",
        "\n",
        "             # Add suffix to column names\n",
        "            resampled_df.columns = [f\"{col}_{sensor_type.name}\" for col in resampled_df.columns]\n",
        "            processed_streams[sensor_type] = resampled_df\n",
        "            print(f\"    Resampled {sensor_type.name} to {len(resampled_df)} rows.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error resampling {sensor_type.name}: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Merge the resampled streams\n",
        "    print(\"  Merging streams...\")\n",
        "    first_stream = True\n",
        "    for sensor_type, resampled_df in processed_streams.items():\n",
        "        if first_stream:\n",
        "            combined_df = resampled_df\n",
        "            first_stream = False\n",
        "        else:\n",
        "            combined_df = pd.merge(combined_df, resampled_df, left_index=True, right_index=True, how='outer')\n",
        "            print(f\"    Merged {sensor_type.name}, shape now: {combined_df.shape}\")\n",
        "\n",
        "    # Interpolate or fill missing values\n",
        "    if combined_df is not None and not combined_df.empty:\n",
        "        print(\"  Forward-filling missing values...\")\n",
        "        combined_df = combined_df.ffill()\n",
        "        combined_df = combined_df.bfill()\n",
        "        combined_df = combined_df.fillna(0)\n",
        "        print(f\"  Final synchronized shape: {combined_df.shape}\")\n",
        "    elif combined_df is not None and combined_df.empty:\n",
        "         print(\"Warning: Combined DataFrame is empty after merging.\")\n",
        "    else:\n",
        "        print(\"Error: No data streams could be processed and merged.\")\n",
        "        return None\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def create_time_windows(sync_data, window_size_sec, overlap_sec):\n",
        "    \"\"\"\n",
        "    Creates time-windowed chunks from synchronized data (single DataFrame with datetime index).\n",
        "    Yields dictionaries containing data for each sensor type within the window.\n",
        "    \"\"\"\n",
        "    if sync_data is None or sync_data.empty:\n",
        "        print(\"Error: Cannot create windows from empty synchronized data.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Creating time windows (size: {window_size_sec}s, overlap: {overlap_sec}s)...\")\n",
        "    window_delta = pd.Timedelta(seconds=window_size_sec)\n",
        "    step_delta = pd.Timedelta(seconds=window_size_sec - overlap_sec)\n",
        "\n",
        "    if step_delta.total_seconds() <= 0: print(\"Error: Overlap cannot be >= window size.\"); return\n",
        "\n",
        "    start_time = sync_data.index.min()\n",
        "    end_time = sync_data.index.max()\n",
        "    current_time = start_time\n",
        "    window_count = 0\n",
        "\n",
        "    while current_time + window_delta <= end_time:\n",
        "        window_end = current_time + window_delta\n",
        "        window_df = sync_data[(sync_data.index >= current_time) & (sync_data.index < window_end)]\n",
        "\n",
        "        if window_df.empty: current_time += step_delta; continue\n",
        "\n",
        "        # Split the combined window_df back into chunks per original sensor type\n",
        "        window_chunks = {}\n",
        "        for sensor_type in SensorType:\n",
        "            sensor_suffix = f\"_{sensor_type.name}\"\n",
        "            # Handle PIR specifically if its columns aren't locations but 'name' etc.\n",
        "            if sensor_type == SensorType.PIR:\n",
        "                 # Find columns that were originally from PIR (use suffix)\n",
        "                 pir_cols_with_suffix = [col for col in window_df.columns if col.endswith(sensor_suffix)]\n",
        "                 if pir_cols_with_suffix:\n",
        "                     sensor_chunk = window_df[pir_cols_with_suffix].copy()\n",
        "                     # Rename columns back (e.g., 'bath_PIR' -> 'bath')\n",
        "                     # This assumes the resampled PIR df has location names as columns\n",
        "                     sensor_chunk.columns = [col.replace(sensor_suffix, '') for col in pir_cols_with_suffix]\n",
        "                     # Ensure all location columns exist, fill missing with 0\n",
        "                     for loc in SPHERE_LOCATIONS:\n",
        "                          if loc not in sensor_chunk.columns:\n",
        "                               sensor_chunk[loc] = 0\n",
        "                     window_chunks[sensor_type] = sensor_chunk[SPHERE_LOCATIONS] # Keep only location columns\n",
        "                 # else: PIR data wasn't successfully merged/resampled\n",
        "\n",
        "            else: # Handle other sensor types\n",
        "                sensor_cols = [col for col in window_df.columns if col.endswith(sensor_suffix)]\n",
        "                if sensor_cols:\n",
        "                    sensor_chunk = window_df[sensor_cols].copy()\n",
        "                    sensor_chunk.columns = [col.replace(sensor_suffix, '') for col in sensor_cols]\n",
        "                    window_chunks[sensor_type] = sensor_chunk\n",
        "\n",
        "        yield {'timestamp': window_end, 'data': window_chunks}\n",
        "        window_count += 1\n",
        "        current_time += step_delta\n",
        "\n",
        "    print(f\"Generated {window_count} windows.\")\n",
        "\n",
        "\n",
        "# --- Agent Class (Steps 2, 3, 4, 9) ---\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"An agent with unique sensory capabilities analyzing sensor data.\"\"\"\n",
        "\n",
        "    def __init__(self, agent_id, sensor_type, feature_extractors=None, learning_rate=0.1, history_len=10):\n",
        "        self.id = agent_id\n",
        "        self.sensor_type = sensor_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.history = deque(maxlen=history_len)\n",
        "\n",
        "        self.confidence = 0.5\n",
        "        self.activity_accuracy = {act: 0.5 for act in SPHERE_ACTIVITY_NAMES}\n",
        "        self.knowledge = {act: 1.0 / len(SPHERE_ACTIVITY_NAMES) for act in SPHERE_ACTIVITY_NAMES}\n",
        "        self.activity_specialization = {act: 0.5 for act in SPHERE_ACTIVITY_NAMES}\n",
        "        self.transition_model = {}\n",
        "\n",
        "        self.feature_extractors = feature_extractors or self._default_feature_extractors()\n",
        "        self.last_timestamp = None\n",
        "\n",
        "    def _default_feature_extractors(self):\n",
        "        \"\"\"Define default feature extractors based on sensor type (Step 3)\"\"\"\n",
        "        global RESAMPLE_FREQ\n",
        "        try: sampling_rate = 1.0 / pd.Timedelta(RESAMPLE_FREQ).total_seconds()\n",
        "        except NameError: sampling_rate = 20.0; print(f\"Warning: Assuming sampling rate {sampling_rate} Hz.\")\n",
        "\n",
        "        if self.sensor_type == SensorType.ACCELEROMETER:\n",
        "            return {\n",
        "                'mean': lambda x: np.nanmean(x, axis=0) if x.shape[0] > 0 else np.zeros(3),\n",
        "                'std': lambda x: np.nanstd(x, axis=0) if x.shape[0] > 0 else np.zeros(3),\n",
        "                'max': lambda x: np.nanmax(x, axis=0) if x.shape[0] > 0 else np.zeros(3),\n",
        "                'min': lambda x: np.nanmin(x, axis=0) if x.shape[0] > 0 else np.zeros(3),\n",
        "                'range': lambda x: np.ptp(x[~np.isnan(x).any(axis=1)], axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 0 else np.zeros(3),\n",
        "                'median': lambda x: np.nanmedian(x, axis=0) if x.shape[0] > 0 else np.zeros(3),\n",
        "                'energy': lambda x: np.sum(np.square(x[~np.isnan(x).any(axis=1)]), axis=0) / x.shape[0] if x.shape[0] > 0 else np.zeros(3),\n",
        "                'iqr': lambda x: np.subtract(*np.nanpercentile(x[~np.isnan(x).any(axis=1)], [75, 25], axis=0)) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 1 else np.zeros(3),\n",
        "                'fft_energy': lambda x: self._calculate_fft_energy(x, sampling_rate) if x.shape[0] > 1 else np.zeros(3),\n",
        "                'fft_peak_freq': lambda x: self._calculate_fft_peak_freq(x, sampling_rate) if x.shape[0] > 1 else np.zeros(3),\n",
        "            }\n",
        "        elif self.sensor_type == SensorType.PIR:\n",
        "             # Assumes input 'x' to lambdas will have columns matching SPHERE_LOCATIONS\n",
        "             # after processing in create_time_windows\n",
        "             return {\n",
        "                'sum': lambda x: np.nansum(x.values, axis=0) if x.shape[0] > 0 else np.zeros(len(SPHERE_LOCATIONS)),\n",
        "                'any': lambda x: np.nanmax(x.values, axis=0).astype(int) if x.shape[0] > 0 else np.zeros(len(SPHERE_LOCATIONS)),\n",
        "                'count': lambda x: np.nansum(x.values > 0, axis=0) if x.shape[0] > 0 else np.zeros(len(SPHERE_LOCATIONS)),\n",
        "            }\n",
        "        elif self.sensor_type == SensorType.RSSI:\n",
        "             num_aps_init = 4\n",
        "             return {\n",
        "                'mean': lambda x: np.nanmean(x, axis=0) if x.shape[0] > 0 else np.full(num_aps_init, -100.0),\n",
        "                'std': lambda x: np.nanstd(x, axis=0) if x.shape[0] > 0 else np.zeros(num_aps_init),\n",
        "                'max': lambda x: np.nanmax(x, axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 0 else np.full(num_aps_init, -100.0),\n",
        "                'min': lambda x: np.nanmin(x, axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 0 else np.full(num_aps_init, -100.0),\n",
        "                'diff': lambda x: np.nanmax(x, axis=0) - np.nanmin(x, axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 1 else np.zeros(num_aps_init),\n",
        "                'stability': lambda x: 1.0 / (1.0 + np.nanstd(x, axis=0)) if x.shape[0] > 0 else np.zeros(num_aps_init)\n",
        "            }\n",
        "        elif self.sensor_type == SensorType.VIDEO:\n",
        "             return {\n",
        "                'center_mean': lambda x: np.nanmean(x[['centre_2d_x', 'centre_2d_y']].values, axis=0) if x.shape[0] > 0 else np.zeros(2),\n",
        "                'center_std': lambda x: np.nanstd(x[['centre_2d_x', 'centre_2d_y']].values, axis=0) if x.shape[0] > 0 else np.zeros(2),\n",
        "                'area_mean': lambda x: self._calculate_area(x, 'mean') if x.shape[0] > 0 else np.zeros(1),\n",
        "                'area_std': lambda x: self._calculate_area(x, 'std') if x.shape[0] > 0 else np.zeros(1),\n",
        "                'aspect_ratio_mean': lambda x: self._calculate_aspect_ratio(x, 'mean') if x.shape[0] > 0 else np.zeros(1),\n",
        "                'movement_mean': lambda x: self._calculate_movement(x, 'mean') if x.shape[0] > 1 else np.zeros(1),\n",
        "                'height_mean': lambda x: self._calculate_height(x, 'mean') if x.shape[0] > 0 else np.zeros(1),\n",
        "                'y_center_mean': lambda x: np.nanmean(x['centre_2d_y'].values) if x.shape[0] > 0 else np.zeros(1),\n",
        "            }\n",
        "        else: return {'identity': lambda x: x}\n",
        "\n",
        "    # --- Feature Calculation Helpers ---\n",
        "    # (Methods _calculate_fft_energy, _calculate_fft_peak_freq, _calculate_area,\n",
        "    #  _calculate_aspect_ratio, _calculate_movement, _calculate_height remain the same)\n",
        "    def _calculate_fft_energy(self, data, sampling_rate):\n",
        "        energies = []\n",
        "        n_samples = data.shape[0]\n",
        "        if n_samples == 0: return np.zeros(data.shape[1])\n",
        "        for i in range(data.shape[1]):\n",
        "            col_data = data[:, i]; valid_data = col_data[~np.isnan(col_data)]; n_valid = len(valid_data)\n",
        "            if n_valid < 2: energies.append(0); continue\n",
        "            fft_values = rfft(valid_data); fft_power = np.abs(fft_values)**2 / n_valid; energies.append(np.sum(fft_power))\n",
        "        return np.array(energies)\n",
        "\n",
        "    def _calculate_fft_peak_freq(self, data, sampling_rate):\n",
        "        peak_freqs = []\n",
        "        n_samples = data.shape[0]\n",
        "        if n_samples == 0: return np.zeros(data.shape[1])\n",
        "        for i in range(data.shape[1]):\n",
        "            col_data = data[:, i]; valid_data = col_data[~np.isnan(col_data)]; n_valid = len(valid_data)\n",
        "            if n_valid < 2 or sampling_rate <= 0: peak_freqs.append(0); continue\n",
        "            freqs = rfftfreq(n_valid, 1.0 / sampling_rate); fft_values = rfft(valid_data); fft_power = np.abs(fft_values)**2\n",
        "            valid_freq_indices = np.arange(len(freqs))\n",
        "            if len(fft_power) > 1 :\n",
        "                 peak_index_rel = np.argmax(fft_power[1:]); peak_index_abs = valid_freq_indices[1:][peak_index_rel]\n",
        "                 peak_freqs.append(freqs[peak_index_abs])\n",
        "            else: peak_freqs.append(0)\n",
        "        return np.array(peak_freqs)\n",
        "\n",
        "    def _calculate_area(self, x, stat='mean'):\n",
        "        required_cols = ['bb_2d_br_x', 'bb_2d_br_y', 'bb_2d_tl_x', 'bb_2d_tl_y']\n",
        "        if not all(col in x.columns for col in required_cols): return np.zeros(1)\n",
        "        width = x['bb_2d_br_x'] - x['bb_2d_tl_x']; height = x['bb_2d_br_y'] - x['bb_2d_tl_y']; area = width * height\n",
        "        if area.isnull().all(): return np.zeros(1)\n",
        "        if stat == 'mean': return np.array([np.nanmean(area)])\n",
        "        if stat == 'std': return np.array([np.nanstd(area)])\n",
        "        return np.zeros(1)\n",
        "\n",
        "    def _calculate_aspect_ratio(self, x, stat='mean'):\n",
        "        required_cols = ['bb_2d_br_x', 'bb_2d_br_y', 'bb_2d_tl_x', 'bb_2d_tl_y']\n",
        "        if not all(col in x.columns for col in required_cols): return np.zeros(1)\n",
        "        width = x['bb_2d_br_x'] - x['bb_2d_tl_x']; height = x['bb_2d_br_y'] - x['bb_2d_tl_y']\n",
        "        valid_mask = (height != 0) & (~height.isnull()) & (~width.isnull())\n",
        "        if not valid_mask.any(): return np.zeros(1)\n",
        "        ratio = pd.Series(np.nan, index=x.index); ratio.loc[valid_mask] = width.loc[valid_mask] / height.loc[valid_mask]\n",
        "        if ratio.isnull().all(): return np.zeros(1)\n",
        "        if stat == 'mean': return np.array([np.nanmean(ratio)])\n",
        "        if stat == 'std': return np.array([np.nanstd(ratio)])\n",
        "        return np.zeros(1)\n",
        "\n",
        "    def _calculate_movement(self, x, stat='mean'):\n",
        "        required_cols = ['centre_2d_x', 'centre_2d_y']\n",
        "        if not all(col in x.columns for col in required_cols) or x.shape[0] < 2: return np.zeros(1)\n",
        "        center_x = x['centre_2d_x']; center_y = x['centre_2d_y']\n",
        "        diff_x = center_x - center_x.shift(1); diff_y = center_y - center_y.shift(1)\n",
        "        movement = np.sqrt(diff_x**2 + diff_y**2)\n",
        "        if movement.isnull().all(): return np.zeros(1)\n",
        "        if stat == 'mean': return np.array([np.nanmean(movement)])\n",
        "        if stat == 'std': return np.array([np.nanstd(movement)])\n",
        "        return np.zeros(1)\n",
        "\n",
        "    def _calculate_height(self, x, stat='mean'):\n",
        "        required_cols = ['bb_2d_br_y', 'bb_2d_tl_y']\n",
        "        if not all(col in x.columns for col in required_cols): return np.zeros(1)\n",
        "        height = x['bb_2d_br_y'] - x['bb_2d_tl_y']\n",
        "        if height.isnull().all(): return np.zeros(1)\n",
        "        if stat == 'mean': return np.array([np.nanmean(height)])\n",
        "        if stat == 'std': return np.array([np.nanstd(height)])\n",
        "        return np.zeros(1)\n",
        "\n",
        "    # --- Core Processing Logic ---\n",
        "    def process_reading(self, timestamp, data_chunk, ground_truth_activity=None):\n",
        "        \"\"\"Process a chunk of sensor data, update knowledge, return interpretation.\"\"\"\n",
        "        self.last_timestamp = timestamp\n",
        "\n",
        "        if data_chunk is None or (isinstance(data_chunk, pd.DataFrame) and data_chunk.empty):\n",
        "             default_scores = {act: 1.0 / len(SPHERE_ACTIVITY_NAMES) for act in SPHERE_ACTIVITY_NAMES}\n",
        "             return {'agent_id': self.id, 'timestamp': timestamp, 'activity_scores': default_scores, 'confidence': 0.1, 'prediction': None, 'features': None, 'error': 'Missing data'}\n",
        "\n",
        "        features = self._extract_features(data_chunk)\n",
        "        if not features:\n",
        "             default_scores = {act: 1.0 / len(SPHERE_ACTIVITY_NAMES) for act in SPHERE_ACTIVITY_NAMES}\n",
        "             return {'agent_id': self.id, 'timestamp': timestamp, 'activity_scores': default_scores, 'confidence': 0.1, 'prediction': None, 'features': features, 'error': 'Feature extraction failed'}\n",
        "\n",
        "        activity_scores = self._determine_activity_scores(features)\n",
        "\n",
        "        if not activity_scores: predicted_activity = None\n",
        "        else:\n",
        "            scores_with_noise = {k: v + np.random.rand()*1e-9 for k, v in activity_scores.items()}\n",
        "            predicted_activity = max(scores_with_noise, key=scores_with_noise.get)\n",
        "\n",
        "        if ground_truth_activity is not None:\n",
        "            self.update_knowledge(features, activity_scores, predicted_activity, ground_truth_activity)\n",
        "\n",
        "        self.history.append((timestamp, features, activity_scores, predicted_activity))\n",
        "\n",
        "        return {\n",
        "            'agent_id': self.id, 'timestamp': timestamp, 'sensor_type': self.sensor_type,\n",
        "            'activity_scores': activity_scores, 'confidence': self.confidence,\n",
        "            'activity_specialization': self.activity_specialization,\n",
        "            'prediction': predicted_activity, 'features': features\n",
        "        }\n",
        "\n",
        "    def _extract_features(self, data_chunk):\n",
        "        \"\"\"Extract features from data based on sensor type. Assumes column names are standardized.\"\"\"\n",
        "        features = {}\n",
        "        required_columns_present = True\n",
        "\n",
        "        try:\n",
        "            if self.sensor_type == SensorType.ACCELEROMETER:\n",
        "                 required_cols = ['x', 'y', 'z']\n",
        "                 if all(col in data_chunk.columns for col in required_cols):\n",
        "                     accel_data = data_chunk[required_cols].values\n",
        "                     for name, extractor in self.feature_extractors.items(): features[name] = extractor(accel_data)\n",
        "                 else: required_columns_present = False\n",
        "            elif self.sensor_type == SensorType.PIR:\n",
        "                 required_cols = SPHERE_LOCATIONS # Expects columns named like locations\n",
        "                 if all(col in data_chunk.columns for col in required_cols):\n",
        "                    pir_data = data_chunk[required_cols] # Keep as DataFrame for lambda\n",
        "                    for name, extractor in self.feature_extractors.items(): features[name] = extractor(pir_data)\n",
        "                 else: required_columns_present = False\n",
        "            elif self.sensor_type == SensorType.RSSI:\n",
        "                 rssi_columns = [col for col in data_chunk.columns if col.startswith('AP') or 'rssi' in col.lower()]\n",
        "                 if rssi_columns and all(col in data_chunk.columns for col in rssi_columns):\n",
        "                     rssi_data = data_chunk[rssi_columns].apply(pd.to_numeric, errors='coerce').values\n",
        "                     self.feature_extractors = self._update_num_aps(rssi_data.shape[1])\n",
        "                     for name, extractor in self.feature_extractors.items(): features[name] = extractor(rssi_data)\n",
        "                 else: required_columns_present = False\n",
        "            elif self.sensor_type == SensorType.VIDEO:\n",
        "                 required_cols = ['centre_2d_x', 'centre_2d_y', 'bb_2d_br_x', 'bb_2d_br_y', 'bb_2d_tl_x', 'bb_2d_tl_y']\n",
        "                 if all(col in data_chunk.columns for col in required_cols):\n",
        "                     video_data = data_chunk[required_cols].apply(pd.to_numeric, errors='coerce')\n",
        "                     for name, extractor in self.feature_extractors.items(): features[name] = extractor(video_data)\n",
        "                 else: required_columns_present = False\n",
        "\n",
        "            if not required_columns_present: return {}\n",
        "\n",
        "            # Flatten feature dictionary\n",
        "            flat_features = {}\n",
        "            for name, value in features.items():\n",
        "                if isinstance(value, (np.ndarray, list)):\n",
        "                    valid_values = value[~np.isnan(value)] if isinstance(value, np.ndarray) else [v for v in value if pd.notna(v)]\n",
        "                    if len(valid_values) > 0:\n",
        "                        if len(value) > 1:\n",
        "                            for i, v in enumerate(value): flat_features[f\"{name}_{i}\"] = v if pd.notna(v) else 0\n",
        "                        elif len(value) == 1: flat_features[name] = value[0] if pd.notna(value[0]) else 0\n",
        "                elif pd.notna(value): flat_features[name] = value\n",
        "            return flat_features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting features for Agent {self.id} ({self.sensor_type}): {e}\")\n",
        "            traceback.print_exc()\n",
        "            return {}\n",
        "\n",
        "    def _update_num_aps(self, num_found):\n",
        "        \"\"\"Helper to update RSSI feature lambdas if num_aps differs.\"\"\"\n",
        "        if self.sensor_type == SensorType.RSSI:\n",
        "             num_aps = num_found\n",
        "             try: current_lambda_dim = len(self.feature_extractors['mean'](np.array([[]])))\n",
        "             except: current_lambda_dim = -1\n",
        "             if num_aps != current_lambda_dim and num_aps > 0: # Add check for num_aps > 0\n",
        "                 print(f\"  Agent {self.id}: Updating RSSI feature extractors for {num_aps} APs.\")\n",
        "                 return {\n",
        "                    'mean': lambda x: np.nanmean(x, axis=0) if x.shape[0] > 0 else np.full(num_aps, -100.0),\n",
        "                    'std': lambda x: np.nanstd(x, axis=0) if x.shape[0] > 0 else np.zeros(num_aps),\n",
        "                    'max': lambda x: np.nanmax(x, axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 0 else np.full(num_aps, -100.0),\n",
        "                    'min': lambda x: np.nanmin(x, axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 0 else np.full(num_aps, -100.0),\n",
        "                    'diff': lambda x: np.nanmax(x, axis=0) - np.nanmin(x, axis=0) if x.shape[0] > 0 and np.sum(~np.isnan(x)) > 1 else np.zeros(num_aps),\n",
        "                    'stability': lambda x: 1.0 / (1.0 + np.nanstd(x, axis=0)) if x.shape[0] > 0 else np.zeros(num_aps)\n",
        "                }\n",
        "        return self.feature_extractors\n",
        "\n",
        "    # --- CORRECTED INDENTATION & REFINED SCORING LOGIC ---\n",
        "    def _determine_activity_scores(self, features):\n",
        "        \"\"\"Determine confidence scores for each activity based on extracted features.\"\"\"\n",
        "        if not features: return {act: 1.0 / len(SPHERE_ACTIVITY_NAMES) for act in SPHERE_ACTIVITY_NAMES}\n",
        "        scores = self.knowledge.copy(); base_multiplier = 1.0\n",
        "        try:\n",
        "            if self.sensor_type == SensorType.ACCELEROMETER:\n",
        "                std_sum=features.get('std_0',0)+features.get('std_1',0)+features.get('std_2',0); energy_sum=features.get('energy_0',0)+features.get('energy_1',0)+features.get('energy_2',0)\n",
        "                if std_sum > 1.5 or energy_sum > 1.0:\n",
        "                    for act, type in SPHERE_ACTIVITIES.items():\n",
        "                        if type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 1.5)\n",
        "                        elif type == ActivityType.TRANSITION: scores[act] *= (base_multiplier * 1.2)\n",
        "                        elif type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 0.5)\n",
        "                    if features.get('fft_peak_freq_2',0)>1.5 and features.get('range_2',0)>5.0: scores['a_jump'] *= 1.5\n",
        "                    elif features.get('std_0',0)>1.0 or features.get('std_1',0)>1.0: scores['a_walk'] *= 1.2; scores['a_loadwalk'] *= 1.2\n",
        "                elif std_sum < 0.3 and energy_sum < 0.2:\n",
        "                     for act, type in SPHERE_ACTIVITIES.items():\n",
        "                        if type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 1.5)\n",
        "                        elif type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 0.5)\n",
        "                     mean_z=features.get('mean_2',0); mean_y=features.get('mean_1',0); mean_x=features.get('mean_0',0)\n",
        "                     mag=np.sqrt(mean_x**2+mean_y**2+mean_z**2); norm_x,norm_y,norm_z=(mean_x/mag,mean_y/mag,mean_z/mag) if mag>1e-6 else (0,0,0)\n",
        "                     if norm_z > 0.8: scores['p_stand'] *= 1.4\n",
        "                     elif abs(norm_x)>0.7 or abs(norm_y)>0.7 : scores['p_lie'] *= 1.4\n",
        "                     else: scores['p_sit'] *= 1.3\n",
        "                else:\n",
        "                    for act, type in SPHERE_ACTIVITIES.items():\n",
        "                         if type == ActivityType.TRANSITION: scores[act] *= (base_multiplier * 1.4)\n",
        "                         elif type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 0.8)\n",
        "                         elif type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 0.8)\n",
        "            elif self.sensor_type == SensorType.PIR:\n",
        "                total_count=sum(features.get(f'count_{i}',0) for i in range(len(SPHERE_LOCATIONS))); num_active_zones=sum(features.get(f'any_{i}',0) for i in range(len(SPHERE_LOCATIONS)))\n",
        "                if total_count > 3 or num_active_zones > 1:\n",
        "                    for act, type in SPHERE_ACTIVITIES.items():\n",
        "                         if type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 1.4)\n",
        "                         elif type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 0.6)\n",
        "                elif total_count == 0:\n",
        "                     for act, type in SPHERE_ACTIVITIES.items():\n",
        "                         if type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 1.2)\n",
        "                         elif type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 0.8)\n",
        "            elif self.sensor_type == SensorType.RSSI:\n",
        "                num_aps=len([k for k in features if k.startswith('std_')]); avg_std=np.mean([features.get(f'std_{i}',100) for i in range(num_aps)]) if num_aps > 0 else 100\n",
        "                if avg_std > 3.0:\n",
        "                     for act, type in SPHERE_ACTIVITIES.items():\n",
        "                        if type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 1.3)\n",
        "                        elif type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 0.7)\n",
        "                elif avg_std < 1.0:\n",
        "                     for act, type in SPHERE_ACTIVITIES.items():\n",
        "                        if type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 1.3)\n",
        "                        elif type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 0.7)\n",
        "            elif self.sensor_type == SensorType.VIDEO:\n",
        "                aspect=features.get('aspect_ratio_mean',1.0); move=features.get('movement_mean',0.0); height=features.get('height_mean',0.0); y_center=features.get('y_center_mean',0.0)\n",
        "                MV_HI=15.0; MV_LO=3.0; ASP_TALL=0.6; ASP_WIDE=1.3; H_TALL=150; H_SHORT=70; Y_LOW=300\n",
        "                if move > MV_HI:\n",
        "                     for act, type in SPHERE_ACTIVITIES.items():\n",
        "                        if type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 1.4)\n",
        "                        elif type == ActivityType.TRANSITION: scores[act] *= (base_multiplier * 1.2)\n",
        "                        elif type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 0.6)\n",
        "                elif move < MV_LO:\n",
        "                    for act, type in SPHERE_ACTIVITIES.items():\n",
        "                        if type == ActivityType.POSTURE: scores[act] *= (base_multiplier * 1.4)\n",
        "                        elif type == ActivityType.AMBULATION: scores[act] *= (base_multiplier * 0.6)\n",
        "                    if aspect < ASP_TALL and height > H_TALL: scores['p_stand'] *= 1.5\n",
        "                    elif aspect > ASP_WIDE and y_center > Y_LOW: scores['p_lie'] *= 1.5\n",
        "                    elif height < H_SHORT and aspect > 0.8: scores['p_squat'] *= 1.2; scores['p_kneel'] *= 1.2\n",
        "                    else: scores['p_sit'] *= 1.3; scores['p_bent'] *= 1.2\n",
        "        except KeyError as e: print(f\"Warning: Agent {self.id} missing feature key during scoring: {e}\")\n",
        "        except Exception as e: print(f\"Error during scoring for Agent {self.id}: {e}\"); traceback.print_exc()\n",
        "        if self.history:\n",
        "            last_pred=self.history[-1][3]\n",
        "            if last_pred is not None and last_pred in scores: scores[last_pred] *= (1.0 + 0.1)\n",
        "        total=sum(scores.values())\n",
        "        if total > 1e-9:\n",
        "            norm_scores={act: max(0, s / total) for act, s in scores.items()}; final_total=sum(norm_scores.values())\n",
        "            if final_total > 1e-9: norm_scores = {act: s / final_total for act, s in norm_scores.items()}\n",
        "            else: norm_scores = {act: 1.0 / len(SPHERE_ACTIVITY_NAMES) for act in SPHERE_ACTIVITY_NAMES}\n",
        "        else: norm_scores = {act: 1.0 / len(SPHERE_ACTIVITY_NAMES) for act in SPHERE_ACTIVITY_NAMES}\n",
        "        return norm_scores\n",
        "\n",
        "    def update_knowledge(self, features, activity_scores, prediction, ground_truth):\n",
        "        \"\"\"Update agent's confidence, knowledge, and specialization.\"\"\"\n",
        "        alpha = self.learning_rate\n",
        "        if prediction == ground_truth:\n",
        "            self.confidence=(1-alpha)*self.confidence+alpha*1.0; self.activity_accuracy[prediction]=(1-alpha)*self.activity_accuracy[prediction]+alpha*1.0; self.activity_specialization[prediction]=(1-alpha)*self.activity_specialization[prediction]+alpha*1.0\n",
        "        else:\n",
        "            self.confidence=(1-alpha)*self.confidence+alpha*0.0\n",
        "            if prediction is not None: self.activity_accuracy[prediction]=(1-alpha)*self.activity_accuracy[prediction]+alpha*0.0; self.activity_specialization[prediction]=max(0.01,(1-alpha)*self.activity_specialization[prediction]+alpha*0.3)\n",
        "            self.activity_accuracy[ground_truth]=(1-alpha)*self.activity_accuracy[ground_truth]+alpha*0.3; self.activity_specialization[ground_truth]=max(0.01,(1-alpha)*self.activity_specialization[ground_truth]+alpha*0.4)\n",
        "        beta=alpha*0.5; current_knowledge_sum=sum(self.knowledge.values())\n",
        "        for act, score in activity_scores.items(): self.knowledge[act]=(1-beta)*self.knowledge[act]+beta*score*current_knowledge_sum\n",
        "        total_knowledge=sum(self.knowledge.values())\n",
        "        if total_knowledge > 1e-9: self.knowledge = {act: k / total_knowledge for act, k in self.knowledge.items()}\n",
        "\n",
        "# --- SwarmQueen Integration System ---\n",
        "class SwarmQueen:\n",
        "    \"\"\"Manages the swarm of agents and integrates their outputs.\"\"\"\n",
        "    def __init__(self, agents, activity_names, location_names):\n",
        "        self.agents={agent.id: agent for agent in agents}; self.activity_names=activity_names; self.location_names=location_names; self.num_activities=len(activity_names); self.system_history=deque(maxlen=20)\n",
        "        self.location_activity_prob=self._initialize_location_activity_map(); self.confusion_matrix=pd.DataFrame(np.zeros((self.num_activities,self.num_activities)),index=activity_names,columns=activity_names)\n",
        "        self.fusion_confidence_weight=1.0; self.fusion_specialization_weight=1.0; self.temporal_inertia_boost=1.1\n",
        "\n",
        "    def _initialize_location_activity_map(self):\n",
        "        loc_act_map={loc: {act: 1.0/self.num_activities for act in self.activity_names} for loc in self.location_names+['UNKNOWN']}; base_prob=1.0/self.num_activities\n",
        "        def update_probs(location, activity_factors):\n",
        "            if location not in loc_act_map: return\n",
        "            for act, factor in activity_factors.items():\n",
        "                 if act in loc_act_map[location]: loc_act_map[location][act] *= factor\n",
        "            total_prob=sum(loc_act_map[location].values())\n",
        "            if total_prob > 1e-9: loc_act_map[location]={act: p/total_prob for act, p in loc_act_map[location].items()}\n",
        "            else: loc_act_map[location]={act: base_prob for act in self.activity_names}\n",
        "        update_probs('living',{'p_sit':4,'p_lie':2,'a_walk':1.5,'t_sit_stand':1.5,'t_stand_sit':1.5}); update_probs('bed1',{'p_lie':5,'p_sit':2,'t_lie_sit':2,'t_sit_lie':2}); update_probs('bed2',{'p_lie':5,'p_sit':2,'t_lie_sit':2,'t_sit_lie':2})\n",
        "        update_probs('kitchen',{'p_stand':3,'a_walk':2,'p_bent':1.5}); update_probs('bath',{'p_stand':3,'a_walk':1.5,'p_bent':1.5}); update_probs('toilet',{'p_sit':5,'p_stand':1.5,'t_sit_stand':1.5,'t_stand_sit':1.5})\n",
        "        update_probs('stairs',{'a_ascend':6,'a_descend':6,'p_stand':1.5,'a_walk':1.2}); update_probs('hall',{'a_walk':4,'p_stand':2}); update_probs('study',{'p_sit':5,'p_stand':1.5,'t_sit_stand':1.2,'t_stand_sit':1.2})\n",
        "        loc_act_map['UNKNOWN']={act: base_prob for act in self.activity_names}; return loc_act_map\n",
        "\n",
        "    def process_system_reading(self, timestamp, data_chunks_by_sensortype, ground_truth_activity=None, ground_truth_location=None):\n",
        "        agent_outputs={}; agent_locations={}\n",
        "        for agent_id, agent in self.agents.items():\n",
        "            data_chunk=data_chunks_by_sensortype.get(agent.sensor_type,None); gt_for_agent=ground_truth_activity\n",
        "            output=agent.process_reading(timestamp,data_chunk,ground_truth_activity=gt_for_agent); agent_outputs[agent_id]=output\n",
        "            if output and 'error' not in output:\n",
        "                if agent.sensor_type==SensorType.PIR and output.get('features'):\n",
        "                    pir_any=[output['features'].get(f'any_{i}',0) for i in range(len(self.location_names))]\n",
        "                    if sum(pir_any)==1: loc_idx=np.argmax(pir_any); agent_locations[agent_id]={'location':self.location_names[loc_idx],'confidence':agent.confidence}\n",
        "        fused_scores=self._weighted_fusion(agent_outputs); inferred_location=self._determine_location(agent_locations,ground_truth_location)\n",
        "        contextual_scores=self._apply_location_context(fused_scores,inferred_location); final_scores=self._apply_temporal_consistency(contextual_scores)\n",
        "        if not final_scores: final_prediction=None\n",
        "        else: scores_with_noise={k:v+np.random.rand()*1e-9 for k,v in final_scores.items()}; final_prediction=max(scores_with_noise,key=scores_with_noise.get)\n",
        "        self.system_history.append((timestamp,final_prediction,inferred_location,final_scores))\n",
        "        if ground_truth_activity is not None and final_prediction is not None: self.update_confusion_matrix(ground_truth_activity,final_prediction)\n",
        "        return {'timestamp':timestamp,'final_prediction':final_prediction,'final_scores':final_scores,'inferred_location':inferred_location,'agent_outputs':agent_outputs}\n",
        "\n",
        "    def _determine_location(self, agent_locations, ground_truth_location=None):\n",
        "         if not agent_locations: return \"UNKNOWN\"\n",
        "         location_votes=defaultdict(float); total_confidence=0.0\n",
        "         for agent_id, loc_info in agent_locations.items():\n",
        "             conf=loc_info.get('confidence',0.1); loc=loc_info.get('location','UNKNOWN')\n",
        "             if loc != 'UNKNOWN': location_votes[loc]+=conf; total_confidence+=conf\n",
        "         if not location_votes or total_confidence < 0.1:\n",
        "            if self.system_history: last_loc=self.system_history[-1][2]; return last_loc if last_loc != \"UNKNOWN\" else \"UNKNOWN\"\n",
        "            return \"UNKNOWN\"\n",
        "         return max(location_votes,key=location_votes.get)\n",
        "\n",
        "    def _weighted_fusion(self, agent_outputs):\n",
        "        fused_scores={act:0.0 for act in self.activity_names}; total_weight={act:1e-9 for act in self.activity_names}\n",
        "        for agent_id, output in agent_outputs.items():\n",
        "            if not output or 'error' in output or not output.get('activity_scores'): continue\n",
        "            agent_conf=output.get('confidence',0.1); agent_spec=output.get('activity_specialization',{act:0.5 for act in self.activity_names}); agent_scores=output['activity_scores']\n",
        "            for activity, score in agent_scores.items():\n",
        "                if activity not in fused_scores: continue\n",
        "                conf_term=max(0.01,agent_conf)**self.fusion_confidence_weight; spec_term=max(0.01,agent_spec.get(activity,0.5))**self.fusion_specialization_weight; weight=conf_term*spec_term\n",
        "                fused_scores[activity]+=score*weight; total_weight[activity]+=weight\n",
        "        for activity in fused_scores: fused_scores[activity]/=total_weight[activity]\n",
        "        final_total=sum(fused_scores.values())\n",
        "        if final_total > 1e-9: fused_scores={act:s/final_total for act,s in fused_scores.items()}\n",
        "        else: fused_scores={act:1.0/self.num_activities for act in self.activity_names}\n",
        "        return fused_scores\n",
        "\n",
        "    def _apply_location_context(self, scores, location):\n",
        "        if location not in self.location_activity_prob: location=\"UNKNOWN\"\n",
        "        contextual_scores={}; loc_probs=self.location_activity_prob[location]\n",
        "        for activity, score in scores.items(): prior_prob=loc_probs.get(activity,1.0/self.num_activities); contextual_scores[activity]=score*prior_prob\n",
        "        total_score=sum(contextual_scores.values())\n",
        "        if total_score > 1e-9: contextual_scores={act:s/total_score for act,s in contextual_scores.items()}\n",
        "        else: contextual_scores={act:1.0/self.num_activities for act in self.activity_names}\n",
        "        return contextual_scores\n",
        "\n",
        "    def _apply_temporal_consistency(self, current_scores):\n",
        "        if not self.system_history: return current_scores\n",
        "        last_prediction=self.system_history[-1][1]; smoothed_scores=current_scores.copy()\n",
        "        if last_prediction is not None and last_prediction in smoothed_scores: smoothed_scores[last_prediction]*=self.temporal_inertia_boost\n",
        "        total_score=sum(smoothed_scores.values())\n",
        "        if total_score > 1e-9: smoothed_scores={act:s/total_score for act,s in smoothed_scores.items()}\n",
        "        else: smoothed_scores={act:1.0/self.num_activities for act in self.activity_names}\n",
        "        return smoothed_scores\n",
        "\n",
        "    def update_confusion_matrix(self, ground_truth, prediction):\n",
        "        if ground_truth in self.confusion_matrix.index and prediction in self.confusion_matrix.columns: self.confusion_matrix.loc[ground_truth,prediction]+=1\n",
        "\n",
        "    def get_confusion_matrix(self): return self.confusion_matrix\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Initializing SPHERE Swarm Intelligence System...\")\n",
        "    # San Diego Time: Monday, March 31, 2025 at 4:25 AM PDT\n",
        "    print(f\"Current Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    # --- Configuration ---\n",
        "    DATA_PATH = \"/content/SPHERE_unzipped\" # <<< --- VERIFY YOUR UNZIPPED DATA PATH --- <<<\n",
        "    TARGET_SUBJECT = \"00001\" # <<<--- USE CORRECT SUBJECT ID (e.g., \"00001\") ---<<<\n",
        "    WINDOW_SIZE_SEC = 2.0\n",
        "    OVERLAP_SEC = 1.0\n",
        "    RESAMPLE_FREQ = '50ms' # Corresponds to 20 Hz\n",
        "\n",
        "    # --- Initialize Agents ---\n",
        "    agents_to_use = [\n",
        "        Agent(agent_id=\"Accel_01\", sensor_type=SensorType.ACCELEROMETER, learning_rate=0.05, history_len=10),\n",
        "        Agent(agent_id=\"PIR_01\", sensor_type=SensorType.PIR, learning_rate=0.1, history_len=5),\n",
        "    ]\n",
        "    print(f\"Initialized {len(agents_to_use)} agents.\")\n",
        "\n",
        "    # --- Initialize SwarmQueen ---\n",
        "    queen = SwarmQueen(agents_to_use, SPHERE_ACTIVITY_NAMES, SPHERE_LOCATIONS)\n",
        "    print(\"Initialized SwarmQueen.\")\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    print(\"\\n--- Starting Data Loading and Processing ---\")\n",
        "    print(f\"Target Subject: {TARGET_SUBJECT}\")\n",
        "    print(f\"Attempting to load data from: {DATA_PATH}\")\n",
        "    accel_data = load_sphere_data(DATA_PATH, TARGET_SUBJECT, 'accelerometer')\n",
        "    pir_data = load_sphere_data(DATA_PATH, TARGET_SUBJECT, 'pir')\n",
        "    annotations = load_sphere_data(DATA_PATH, TARGET_SUBJECT, 'annotations')\n",
        "\n",
        "    # --- Robustness Check ---\n",
        "    if accel_data is None or annotations is None:\n",
        "         print(\"\\n--- ERROR: Failed to load essential Accelerometer or Annotation data. Stopping. ---\")\n",
        "    else:\n",
        "        print(\"\\n--- Essential data (Accel, Annotations) loaded successfully. Proceeding... ---\")\n",
        "        if pir_data is None: print(\"--- Warning: Failed to load PIR data correctly. Proceeding without it. ---\")\n",
        "        else: print(\"--- PIR data loaded successfully. ---\")\n",
        "\n",
        "        all_data_streams = { SensorType.ACCELEROMETER: accel_data, SensorType.PIR: pir_data }\n",
        "        sync_data = synchronize_data(all_data_streams, resample_freq=RESAMPLE_FREQ)\n",
        "\n",
        "        if sync_data is None or sync_data.empty: print(\"\\n--- ERROR: Data synchronization failed. Stopping. ---\")\n",
        "        else:\n",
        "            window_generator = create_time_windows(sync_data, WINDOW_SIZE_SEC, OVERLAP_SEC)\n",
        "            print(\"Sorting annotations index...\")\n",
        "            if 'end' not in annotations.columns: print(\"Error: Annotations missing 'end' column.\"); exit()\n",
        "            annotations = annotations.sort_index()\n",
        "\n",
        "            # --- Processing Loop ---\n",
        "            print(\"\\n--- Processing Windows ---\")\n",
        "            all_predictions=[]; all_ground_truths=[]; window_count=0; start_processing_time=time.time()\n",
        "            for window in window_generator:\n",
        "                window_count+=1; window_end_time=window['timestamp']; window_data_chunks=window['data']\n",
        "                ground_truth=None\n",
        "                try: # Ground Truth Lookup\n",
        "                    window_start_time=window_end_time-pd.Timedelta(seconds=WINDOW_SIZE_SEC); window_mid_point=window_start_time+(window_end_time-window_start_time)/2\n",
        "                    matching_annotations=annotations.loc[(annotations.index<=window_mid_point)&(annotations['end']>window_mid_point)]\n",
        "                    if not matching_annotations.empty:\n",
        "                        matched_annotation=matching_annotations.iloc[0]\n",
        "                        activity_col=next((col for col in ['activity','annotation','label'] if col in annotations.columns),None)\n",
        "                        if activity_col: ground_truth=matched_annotation[activity_col]\n",
        "                except Exception as e: print(f\"Error looking up annotation: {e}\"); traceback.print_exc()\n",
        "\n",
        "                system_output=queen.process_system_reading(window_end_time,window_data_chunks,ground_truth_activity=ground_truth)\n",
        "                if ground_truth is not None and ground_truth in SPHERE_ACTIVITY_NAMES: all_ground_truths.append(ground_truth); all_predictions.append(system_output['final_prediction'])\n",
        "                if window_count%100==0: print(f\"  Processed {window_count} windows... Time: {window_end_time.strftime('%H:%M:%S.%f')[:-3]} Pred: {system_output['final_prediction']} (GT: {ground_truth if ground_truth else 'N/A'}) Loc: {system_output['inferred_location']}\")\n",
        "            end_processing_time=time.time(); print(f\"\\n--- Finished processing {window_count} windows in {end_processing_time-start_processing_time:.2f} seconds ---\")\n",
        "\n",
        "            # --- Evaluation ---\n",
        "            print(\"\\n--- Evaluation Results ---\"); final_confusion_matrix=queen.get_confusion_matrix(); print(f\"Collected {len(all_ground_truths)} predictions with valid ground truth.\")\n",
        "            if len(all_ground_truths) > 0 and len(all_predictions) == len(all_ground_truths):\n",
        "                accuracy=accuracy_score(all_ground_truths,all_predictions); print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
        "                unique_labels=sorted(list(set(all_ground_truths)|set(all_predictions))); unique_labels=[label for label in unique_labels if label is not None and label in SPHERE_ACTIVITY_NAMES]\n",
        "                print(\"\\nClassification Report:\");\n",
        "                try: report=classification_report(all_ground_truths,all_predictions,labels=unique_labels,zero_division=0); print(report)\n",
        "                except ValueError as e: print(f\"Could not generate classification report: {e}\")\n",
        "                print(\"\\nFinal Confusion Matrix:\"); cm_labels=sorted(list(set(all_ground_truths)|set(all_predictions))); cm_labels=[l for l in cm_labels if l is not None and l in final_confusion_matrix.index and l in final_confusion_matrix.columns]\n",
        "                if cm_labels:\n",
        "                    cm_display=final_confusion_matrix.loc[cm_labels,cm_labels]; print(cm_display)\n",
        "                    try:\n",
        "                        plt.figure(figsize=(12,10)); sns.heatmap(cm_display,annot=True,fmt=\".0f\",cmap=\"Blues\",xticklabels=cm_labels,yticklabels=cm_labels); plt.title(f'System Confusion Matrix (Subject: {TARGET_SUBJECT})')\n",
        "                        plt.ylabel('True Label'); plt.xlabel('Predicted Label'); plt.xticks(rotation=45,ha='right'); plt.yticks(rotation=0); plt.tight_layout()\n",
        "                        plot_filename=f\"confusion_matrix_{TARGET_SUBJECT}.png\"; plt.savefig(plot_filename); print(f\"\\nConfusion matrix plot saved as {plot_filename}\"); plt.close()\n",
        "                    except Exception as plot_err: print(f\"Error plotting confusion matrix: {plot_err}\")\n",
        "                else: print(\"\\nCould not generate confusion matrix (no common valid labels found).\")\n",
        "            else:\n",
        "                 if len(all_ground_truths)==0: print(\"\\nEvaluation failed: No valid ground truth labels were found.\"); print(\"Check annotation loading and GT lookup logic.\")\n",
        "                 else: print(\"\\nEvaluation failed: Length mismatch between predictions and ground truth lists.\")\n",
        "\n",
        "    print(\"\\nSystem processing finished (or terminated due to loading/sync error).\")\n",
        "\n"
      ]
    }
  ]
}